config:
    AZURE_SUBSCRIPTION_ID: "<YOUR-SUBSCRIPTION-ID>" # Please modify to your subscription
    AZURE_RESOURCE_GROUP: "<YOUR-RESOURCE-GROUP>" # Please modify to your Azure resource group
    AZURE_WORKSPACE: "<YOUR-AZURE-WORKSPACE>" # Please modify to your Azure workspace
    AZURE_SFT_DATA_NAME: "sft-data" # Please modify to your AzureML data name
    AZURE_DPO_DATA_NAME: "dpo-data" # Please modify to your AzureML data name
    SFT_DATA_DIR: "./sft_dataset"
    DPO_DATA_DIR: "./dpo_dataset"
    CLOUD_DIR: "./cloud"
    HF_MODEL_NAME_OR_PATH: "microsoft/Phi-3.5-mini-instruct"
    HF_TOKEN: "<YOUR-HF-TOKEN>" # Please modify to your Hugging Face token
    IS_DEBUG: true
    USE_LOWPRIORITY_VM: false

train:
    azure_env_name: "torchtune-2024-10-27" # Please modify to your AzureML env name
    azure_compute_cluster_name: "gpu-cluster-a100"
    azure_compute_cluster_size: "Standard_NC24ads_A100_v4" # 1 x A100 (80GB)
    # azure_compute_cluster_name="gpu-cluster-a100-2"
    # azure_compute_cluster_size="Standard_NC48ads_A100_v4"
    epoch: 1
    train_batch_size: 8
    eval_batch_size: 8
    model_dir: "./outputs"
    wandb_api_key: "" # Please modify to your W&B API key if you want to use W&B
    wandb_project: "" # Please modify to your W&B project name
    wandb_watch: "gradients"

serve:
    azure_env_name: "llm-serving-2024-10-27" # Please modify to your AzureML env name
    azure_model_name: "phi3-finetune-2024-10-27" # Please modify to your AzureML model name
    azure_endpoint_name: "phi3-endpoint-2024-10-27"
    azure_deployment_name: "phi3-blue"
    azure_serving_cluster_size: "Standard_NC24ads_A100_v4"
